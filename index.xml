<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>ameya.karkal</title>
    <link>https://ameyakarkal.github.io/</link>
    <description>Recent content on ameya.karkal</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 03 May 2020 00:00:00 -0500</lastBuildDate><atom:link href="https://ameyakarkal.github.io/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>stack</title>
      <link>https://ameyakarkal.github.io/stack/</link>
      <pubDate>Fri, 12 Jul 2024 00:00:00 -0500</pubDate>
      
      <guid>https://ameyakarkal.github.io/stack/</guid>
      <description> Over the last decade+ I have worked with the following languages / technology stacks in solutions that I have owned and taken to production
frontend backend data ops frameworks React apollo-graphql langauages c-sharp sql java javascript apis dotnet webapi dotnet mvc node GraphQL cloud services azure-webapp azure-functions azure-durable-functions azure-cdn azure-api-gateway azure-app-insights log-analytics-workspace azure-redis messaging / async azure-service-bus azure-storage-queue kafka Object Relational Models dapper entity-framework test and perforamance xunit taurus data stores sql-server azure-storage-table elastic-search azure-search dynamoDB azure-synapse powerbi-dataset cloud services azure-data-factory azure-synapse operations azure-devops azure-pipeline azure-repos github-actions terraform terragrunt azure-kubernetes </description>
    </item>
    
    <item>
      <title>me</title>
      <link>https://ameyakarkal.github.io/me/</link>
      <pubDate>Sat, 30 Mar 2024 00:00:00 -0500</pubDate>
      
      <guid>https://ameyakarkal.github.io/me/</guid>
      <description>Software Engineer @ Kangarootime Inc Nov 2023 - present, 4 mos
dotnet-core aws azure azure-devops terraform postgres graphql
Individual contributor working across multiple product teams delivering microservice-based software solutions powered by kafka Stabilized high risk/reward project for the startup within the first four months of of joining Streamlined delivery of analytic reports enabling data science team Took ownership of multiple solutions deployed on kubernetes built on dotnet, GraphQL BFF catering web and mobile clients Staff Product Developer @ Anthology Inc held positions</description>
    </item>
    
    <item>
      <title>Data &amp; Power BI</title>
      <link>https://ameyakarkal.github.io/projects/powerbi/</link>
      <pubDate>Sun, 03 May 2020 00:00:00 -0500</pubDate>
      
      <guid>https://ameyakarkal.github.io/projects/powerbi/</guid>
      <description>The company that I worked for had an interesting problem to solve. They had recently &amp;ldquo;acquired&amp;rdquo; a consultant who provided custom reporting services to higher education institutions which was highly labor intensive and manual. We were asked to fully automate the workflow incrementally AND onboard existing clients
powerbi azure-storage azure-data-factory azure-web-app powerbi-embeded azure-functions azure-entra
What were the challenges? The existing process was very custom and manual in nature. The consultant custom transformed data files from the institutions, loaded them into an on prem database to perform transformations and imported the results into a power bi report.</description>
    </item>
    
    <item>
      <title>Data &amp; Azure</title>
      <link>https://ameyakarkal.github.io/projects/data-lake/</link>
      <pubDate>Fri, 26 Apr 2019 00:00:00 -0500</pubDate>
      
      <guid>https://ameyakarkal.github.io/projects/data-lake/</guid>
      <description>In 2018, I was involved in designing and building a workflow that would allow sharing data between multiple products of the same campany on a single enterprise platform. The company had an enterprise contract with Microsoft Azure, with almost all of their infrastructure built and deployed across regions in azure. Building this workflow using the tools available in azure was a no brainer.
Stack azure-data-factory azure-kubernetes-services azure-functions dotnet-core node elasticsearch kanban OKRs azure-devops</description>
    </item>
    
    <item>
      <title>Emails &amp; Serverless</title>
      <link>https://ameyakarkal.github.io/projects/serverless-email/</link>
      <pubDate>Sat, 27 Feb 2016 00:00:00 -0500</pubDate>
      
      <guid>https://ameyakarkal.github.io/projects/serverless-email/</guid>
      <description>I worked on a project that involved sending surveys to students enrolled in higher education degree institutions at end of the semester.
serverless azure-functions storage queue micro-service scaling
What were the challenges? We used a legacy windows service built on dotnet framework with a crusty cron job system built on top of Quartz to send emails The process was chunky and could not scale to the demands of the growing product This was a multi-tenant service however, issues in one tenant affected performance and quality of service offered to other tenants There were too many unknowns about if and when the emails would be delivered, this was more of a spaghetti implementation of the older service It lacked tools for internal support people and clients to manage expectations and achieve their goals Solution?</description>
    </item>
    
  </channel>
</rss>
