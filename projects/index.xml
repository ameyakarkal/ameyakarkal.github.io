<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Projects on ameya.karkal</title>
    <link>https://ameyakarkal.github.io/projects/</link>
    <description>Recent content in Projects on ameya.karkal</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 03 May 2020 00:00:00 -0500</lastBuildDate><atom:link href="https://ameyakarkal.github.io/projects/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Data &amp; Power BI</title>
      <link>https://ameyakarkal.github.io/projects/powerbi/</link>
      <pubDate>Sun, 03 May 2020 00:00:00 -0500</pubDate>
      
      <guid>https://ameyakarkal.github.io/projects/powerbi/</guid>
      <description>The company that I worked for had an interesting problem to solve. They had recently &amp;ldquo;acquired&amp;rdquo; a consultant who provided custom reporting services to higher education institutions which was highly labor intensive and manual. We were asked to fully automate the workflow incrementally AND onboard existing clients
powerbi azure-storage azure-data-factory azure-web-app powerbi-embeded azure-functions azure-entra
What were the challenges? The existing process was very custom and manual in nature. The consultant custom transformed data files from the institutions, loaded them into an on prem database to perform transformations and imported the results into a power bi report.</description>
    </item>
    
    <item>
      <title>Data &amp; Azure</title>
      <link>https://ameyakarkal.github.io/projects/data-lake/</link>
      <pubDate>Fri, 26 Apr 2019 00:00:00 -0500</pubDate>
      
      <guid>https://ameyakarkal.github.io/projects/data-lake/</guid>
      <description>In 2018, I was involved in designing and building a workflow that would allow sharing data between multiple products of the same campany on a single enterprise platform. The company had an enterprise contract with Microsoft Azure, with almost all of their infrastructure built and deployed across regions in azure. Building this workflow using the tools available in azure was a no brainer.
Stack azure-data-factory azure-kubernetes-services azure-functions dotnet-core node elasticsearch kanban OKRs azure-devops</description>
    </item>
    
    <item>
      <title>Emails &amp; Serverless</title>
      <link>https://ameyakarkal.github.io/projects/serverless-email/</link>
      <pubDate>Sat, 27 Feb 2016 00:00:00 -0500</pubDate>
      
      <guid>https://ameyakarkal.github.io/projects/serverless-email/</guid>
      <description>I worked on a project that involved sending surveys to students enrolled in higher education degree institutions at end of the semester.
serverless azure-functions storage queue micro-service scaling
What were the challenges? We used a legacy windows service built on dotnet framework with a crusty cron job system built on top of Quartz to send emails The process was chunky and could not scale to the demands of the growing product This was a multi-tenant service however, issues in one tenant affected performance and quality of service offered to other tenants There were too many unknowns about if and when the emails would be delivered, this was more of a spaghetti implementation of the older service It lacked tools for internal support people and clients to manage expectations and achieve their goals Solution?</description>
    </item>
    
  </channel>
</rss>
